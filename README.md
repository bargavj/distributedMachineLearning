# Distributed Privacy-Preserving Empirical Risk Minimization
This work combines differential privacy and multi-party computation protocol to achieve distributed machine learning. Based on the paper "Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization" (http://papers.nips.cc/paper/7871-distributed-learning-without-distress-privacy-preserving-empirical-risk-minimization) that has been accepted at NIPS 2018.

The code contains privacy preserving implementation of L2 Regularized Logistic Regression and Linear Regression models.

### Requirements

* Python 2.7 or above
* [Numpy](https://numpy.org)
* [Scikit Learn[](https://scikit-learn.org/stable/)
* [Obliv-C](https://github.com/samee/obliv-c)
* [Absentminded Crypto Toolkit](https://bitbucket.org/jackdoerner/absentminded-crypto-kit/src/master/)

### Code Execution
Run `python model_wrapper.py`
